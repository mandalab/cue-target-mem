{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_path = input(\"Enter the path to the Cox combined memorability file: \")\n",
    "subtlex_path = input(\"Enter the path to the SUBTLEX memorability file: \")\n",
    "concreteness_path = input(\"Enter the path to the Concreteness ratings file: \")\n",
    "boi_means_path = input(\"Enter the path to the BOI means file: \")\n",
    "cox_word_properties_file = input(\"Enter the file path to save all the Cox word properties : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox = pd.read_excel(cox_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cox['Word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtlex = pd.read_excel(subtlex_path)\n",
    "# Create lists to store frequency and contextual diversity counts\n",
    "wf = []\n",
    "cd = []\n",
    "\n",
    "# Get counts for cue words\n",
    "for word in words:\n",
    "    word_data = subtlex[subtlex['Word'] == word]\n",
    "    wf.append(word_data['FREQcount'].values[0] if not word_data.empty else 0)\n",
    "    cd.append(word_data['CDcount'].values[0] if not word_data.empty else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for cues and targets\n",
    "df = pd.DataFrame({\n",
    "    'Word': words,\n",
    "    'Frequency': wf,\n",
    "    'CD': cd\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = pd.read_excel(concreteness_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get concreteness values for cues\n",
    "conc_scores = []\n",
    "for word in words:\n",
    "    word_data = conc[conc['Word'] == word]\n",
    "    conc_scores.append(word_data['Conc.M'].values[0] if not word_data.empty else None)\n",
    "\n",
    "\n",
    "\n",
    "# Add concreteness values to dataframes\n",
    "df['Concreteness'] = conc_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\ANUSKA\n",
      "[nltk_data]     MAITY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to C:\\Users\\ANUSKA\n",
      "[nltk_data]     MAITY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics import edit_distance\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('cmudict')\n",
    "\n",
    "# Load CMU Pronouncing Dictionary\n",
    "cmu = cmudict.dict()\n",
    "\n",
    "# Function to count morphemes\n",
    "def count_morphemes(word):\n",
    "    base_form = wn.morphy(word)\n",
    "    return len(base_form) if base_form is not None else 0\n",
    "\n",
    "# Function to count phonemes\n",
    "def count_phonemes(word):\n",
    "    return len(cmu[word][0]) if word in cmu else 0\n",
    "\n",
    "# Function to calculate orthographic neighborhood (ON) size\n",
    "def orthographic_neighborhood(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    lemmas = set()\n",
    "    for synset in synsets:\n",
    "        lemmas.update(synset.lemma_names())\n",
    "    return len(lemmas)\n",
    "\n",
    "# Function to calculate phonological neighborhood (PN) size\n",
    "def phonological_neighborhood(word):\n",
    "    phonemes = cmu[word][0] if word in cmu else []\n",
    "    neighbors = set()\n",
    "    for w, pronunciations in cmu.items():\n",
    "        for pron in pronunciations:\n",
    "            if edit_distance(pron, phonemes) == 1:\n",
    "                neighbors.add(w)\n",
    "    return len(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for cues\n",
    "morphemes_cues = [count_morphemes(word) for word in words]\n",
    "phonemes_cues = [count_phonemes(word) for word in words]\n",
    "on_cues = [orthographic_neighborhood(word) for word in words]\n",
    "pn_cues = [phonological_neighborhood(word) for word in words]\n",
    "\n",
    "# Add metrics to dataframes\n",
    "df['Morphemes'] = morphemes_cues\n",
    "df['Phonemes'] = phonemes_cues\n",
    "df['ON_Size'] = on_cues\n",
    "df['PN_Size'] = pn_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "\n",
    "# Load CMU Pronouncing Dictionary\n",
    "cmu = cmudict.dict()\n",
    "\n",
    "def count_syllables(word):\n",
    "    return len(cmu[word][0]) if word in cmu else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add letter counts\n",
    "df['Letters'] = df['Word'].apply(len)\n",
    "\n",
    "\n",
    "# Add syllable counts\n",
    "df['Syllables'] = df['Word'].apply(count_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>CD</th>\n",
       "      <th>Concreteness</th>\n",
       "      <th>Morphemes</th>\n",
       "      <th>Phonemes</th>\n",
       "      <th>ON_Size</th>\n",
       "      <th>PN_Size</th>\n",
       "      <th>Letters</th>\n",
       "      <th>Syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accident</td>\n",
       "      <td>4146</td>\n",
       "      <td>2180</td>\n",
       "      <td>3.26</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accounts</td>\n",
       "      <td>534</td>\n",
       "      <td>391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accurate</td>\n",
       "      <td>400</td>\n",
       "      <td>344</td>\n",
       "      <td>1.90</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>achieve</td>\n",
       "      <td>374</td>\n",
       "      <td>317</td>\n",
       "      <td>2.29</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acid</td>\n",
       "      <td>508</td>\n",
       "      <td>323</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>writers</td>\n",
       "      <td>303</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>yards</td>\n",
       "      <td>760</td>\n",
       "      <td>497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>yelled</td>\n",
       "      <td>313</td>\n",
       "      <td>278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>younger</td>\n",
       "      <td>1257</td>\n",
       "      <td>944</td>\n",
       "      <td>2.79</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>youth</td>\n",
       "      <td>858</td>\n",
       "      <td>600</td>\n",
       "      <td>3.28</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Frequency    CD  Concreteness  Morphemes  Phonemes  ON_Size  \\\n",
       "0    accident       4146  2180          3.26          8         8        4   \n",
       "1    accounts        534   391           NaN          7         6       17   \n",
       "2    accurate        400   344          1.90          8         6        3   \n",
       "3     achieve        374   317          2.29          7         4        4   \n",
       "4        acid        508   323          4.25          4         4       25   \n",
       "..        ...        ...   ...           ...        ...       ...      ...   \n",
       "919   writers        303   195           NaN          6         5        2   \n",
       "920     yards        760   497           NaN          4         5       16   \n",
       "921    yelled        313   278           NaN          4         4       11   \n",
       "922   younger       1257   944          2.79          7         5       10   \n",
       "923     youth        858   600          3.28          5         3        8   \n",
       "\n",
       "     PN_Size  Letters  Syllables  \n",
       "0          3        8          8  \n",
       "1          4        8          6  \n",
       "2          3        8          6  \n",
       "3          6        7          4  \n",
       "4          9        4          4  \n",
       "..       ...      ...        ...  \n",
       "919       29        7          5  \n",
       "920       13        5          5  \n",
       "921       16        6          4  \n",
       "922        8        7          5  \n",
       "923       58        5          3  \n",
       "\n",
       "[924 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any column has NaN values\n",
    "nan_check = df_cleaned.isna().any()\n",
    "\n",
    "# Display columns with NaNs (if any)\n",
    "print(\"Columns with NaN values:\" if nan_check.any() else \" No NaN values found in any column.\")\n",
    "print(nan_check[nan_check])  # Only prints columns where NaNs are present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "boi_means = pd.read_csv(boi_means_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.merge(boi_means[['Word', 'Mean']], on='Word', how='left')\n",
    "df_cleaned.rename(columns={'Mean': 'BOI'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_cleaned, cox[['Word', 'Cue Memorability', 'Target Memorability']], on='Word', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>CD</th>\n",
       "      <th>Concreteness</th>\n",
       "      <th>Morphemes</th>\n",
       "      <th>Phonemes</th>\n",
       "      <th>ON_Size</th>\n",
       "      <th>PN_Size</th>\n",
       "      <th>Letters</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>BOI</th>\n",
       "      <th>Cue Memorability</th>\n",
       "      <th>Target Memorability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accident</td>\n",
       "      <td>4146</td>\n",
       "      <td>2180</td>\n",
       "      <td>3.26</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acid</td>\n",
       "      <td>508</td>\n",
       "      <td>323</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>address</td>\n",
       "      <td>2666</td>\n",
       "      <td>1688</td>\n",
       "      <td>3.89</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>administration</td>\n",
       "      <td>387</td>\n",
       "      <td>286</td>\n",
       "      <td>2.78</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>2.240000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>advance</td>\n",
       "      <td>815</td>\n",
       "      <td>654</td>\n",
       "      <td>2.57</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>wise</td>\n",
       "      <td>1452</td>\n",
       "      <td>1046</td>\n",
       "      <td>1.97</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>wooden</td>\n",
       "      <td>367</td>\n",
       "      <td>276</td>\n",
       "      <td>4.61</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>worker</td>\n",
       "      <td>558</td>\n",
       "      <td>418</td>\n",
       "      <td>4.59</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5.086957</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.138889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>worry</td>\n",
       "      <td>14638</td>\n",
       "      <td>5727</td>\n",
       "      <td>2.55</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>youth</td>\n",
       "      <td>858</td>\n",
       "      <td>600</td>\n",
       "      <td>3.28</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.296296</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Frequency    CD  Concreteness  Morphemes  Phonemes  \\\n",
       "0          accident       4146  2180          3.26          8         8   \n",
       "1              acid        508   323          4.25          4         4   \n",
       "2           address       2666  1688          3.89          7         5   \n",
       "3    administration        387   286          2.78         14        13   \n",
       "4           advance        815   654          2.57          7         6   \n",
       "..              ...        ...   ...           ...        ...       ...   \n",
       "409            wise       1452  1046          1.97          4         3   \n",
       "410          wooden        367   276          4.61          6         5   \n",
       "411          worker        558   418          4.59          6         4   \n",
       "412           worry      14638  5727          2.55          5         3   \n",
       "413           youth        858   600          3.28          5         3   \n",
       "\n",
       "     ON_Size  PN_Size  Letters  Syllables       BOI  Cue Memorability  \\\n",
       "0          4        3        8          8  2.818182          0.342857   \n",
       "1         25        9        4          4  3.111111          0.488372   \n",
       "2         18        0        7          5  1.833333          0.173913   \n",
       "3         15        3       14         13  2.240000          0.272727   \n",
       "4         44        2        7          6  1.680000          0.111111   \n",
       "..       ...      ...      ...        ...       ...               ...   \n",
       "409       15      125        4          3  1.360000          0.315789   \n",
       "410        1       26        6          5  3.000000          0.384615   \n",
       "411        5       36        6          4  5.086957          0.269231   \n",
       "412        9       53        5          3  1.680000          0.321429   \n",
       "413        8       58        5          3  3.296296          0.409091   \n",
       "\n",
       "     Target Memorability  \n",
       "0               0.366667  \n",
       "1               0.384615  \n",
       "2               0.258065  \n",
       "3               0.343750  \n",
       "4               0.272727  \n",
       "..                   ...  \n",
       "409             0.250000  \n",
       "410             0.312500  \n",
       "411             0.138889  \n",
       "412             0.192308  \n",
       "413             0.517241  \n",
       "\n",
       "[414 rows x 13 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_excel(cox_word_properties_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Word', 'Frequency', 'CD', 'Concreteness', 'Morphemes', 'Phonemes',\n",
       "       'ON_Size', 'PN_Size', 'Letters', 'Syllables', 'BOI', 'Cue Memorability',\n",
       "       'Target Memorability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base code\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.tools.tools import maybe_unwrap_results\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Type\n",
    "import statsmodels\n",
    "\n",
    "style_talk = 'seaborn-talk'    #refer to plt.style.available\n",
    "\n",
    "class LinearRegDiagnostic():\n",
    "    \"\"\"\n",
    "    Diagnostic plots to identify potential problems in a linear regression fit.\n",
    "    Mainly,\n",
    "        a. non-linearity of data\n",
    "        b. Correlation of error terms\n",
    "        c. non-constant variance\n",
    "        d. outliers\n",
    "        e. high-leverage points\n",
    "        f. collinearity\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 results: Type[statsmodels.regression.linear_model.RegressionResultsWrapper]) -> None:\n",
    "        \"\"\"\n",
    "        For a linear regression model, generates following diagnostic plots:\n",
    "\n",
    "        a. residual\n",
    "        b. qq\n",
    "        c. scale location and\n",
    "        d. leverage\n",
    "\n",
    "        and a table\n",
    "\n",
    "        e. vif\n",
    "\n",
    "        Args:\n",
    "            results (Type[statsmodels.regression.linear_model.RegressionResultsWrapper]):\n",
    "                must be instance of statsmodels.regression.linear_model object\n",
    "\n",
    "        Raises:\n",
    "            TypeError: if instance does not belong to above object\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(results, statsmodels.regression.linear_model.RegressionResultsWrapper) is False:\n",
    "            raise TypeError(\"result must be instance of statsmodels.regression.linear_model.RegressionResultsWrapper object\")\n",
    "\n",
    "        self.results = maybe_unwrap_results(results)\n",
    "\n",
    "        self.y_true = self.results.model.endog\n",
    "        self.y_predict = self.results.fittedvalues\n",
    "        self.xvar = self.results.model.exog\n",
    "        self.xvar_names = self.results.model.exog_names\n",
    "\n",
    "        self.residual = np.array(self.results.resid)\n",
    "        influence = self.results.get_influence()\n",
    "        self.residual_norm = influence.resid_studentized_internal\n",
    "        self.leverage = influence.hat_matrix_diag\n",
    "        self.cooks_distance = influence.cooks_distance[0]\n",
    "        self.nparams = len(self.results.params)\n",
    "        self.nresids = len(self.residual_norm)\n",
    "\n",
    "    def __call__(self, plot_context='seaborn-v0_8-paper', **kwargs):\n",
    "        # print(plt.style.available)\n",
    "        # GH#9157\n",
    "        if plot_context not in plt.style.available:\n",
    "            plot_context = 'default'\n",
    "        with plt.style.context(plot_context):\n",
    "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "            self.residual_plot(ax=ax[0,0])\n",
    "            self.qq_plot(ax=ax[0,1])\n",
    "            self.scale_location_plot(ax=ax[1,0])\n",
    "            self.leverage_plot(\n",
    "                ax=ax[1,1],\n",
    "                high_leverage_threshold = kwargs.get('high_leverage_threshold'),\n",
    "                cooks_threshold = kwargs.get('cooks_threshold'))\n",
    "            plt.show()\n",
    "\n",
    "        return self.vif_table(), fig, ax,\n",
    "\n",
    "    def residual_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Residual vs Fitted Plot\n",
    "\n",
    "        Graphical tool to identify non-linearity.\n",
    "        (Roughly) Horizontal red line is an indicator that the residual has a linear pattern\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        sns.residplot(\n",
    "            x=self.y_predict,\n",
    "            y=self.residual,\n",
    "            lowess=True,\n",
    "            scatter_kws={'alpha': 0.5},\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        residual_abs = np.abs(self.residual)\n",
    "        abs_resid = np.flip(np.argsort(residual_abs), 0)\n",
    "        abs_resid_top_3 = abs_resid[:3]\n",
    "        for i in abs_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.y_predict[i], self.residual[i]),\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Residuals vs Fitted', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Fitted values')\n",
    "        ax.set_ylabel('Residuals')\n",
    "        return ax\n",
    "\n",
    "    def qq_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Standarized Residual vs Theoretical Quantile plot\n",
    "\n",
    "        Used to visually check if residuals are normally distributed.\n",
    "        Points spread along the diagonal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        QQ = ProbPlot(self.residual_norm)\n",
    "        fig = QQ.qqplot(line='45', alpha=0.5, lw=1, ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_norm_resid = np.flip(np.argsort(np.abs(self.residual_norm)), 0)\n",
    "        abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "        for i, x, y in self.__qq_top_resid(QQ.theoretical_quantiles, abs_norm_resid_top_3):\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(x, y),\n",
    "                ha='right',\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Normal Q-Q', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Theoretical Quantiles')\n",
    "        ax.set_ylabel('Standardized Residuals')\n",
    "        return ax\n",
    "\n",
    "    def scale_location_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Sqrt(Standarized Residual) vs Fitted values plot\n",
    "\n",
    "        Used to check homoscedasticity of the residuals.\n",
    "        Horizontal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        residual_norm_abs_sqrt = np.sqrt(np.abs(self.residual_norm))\n",
    "\n",
    "        ax.scatter(self.y_predict, residual_norm_abs_sqrt, alpha=0.5);\n",
    "        sns.regplot(\n",
    "            x=self.y_predict,\n",
    "            y=residual_norm_abs_sqrt,\n",
    "            scatter=False, ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_sq_norm_resid = np.flip(np.argsort(residual_norm_abs_sqrt), 0)\n",
    "        abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
    "        for i in abs_sq_norm_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.y_predict[i], residual_norm_abs_sqrt[i]),\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Scale-Location', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Fitted values')\n",
    "        ax.set_ylabel(r'$\\sqrt{|\\mathrm{Standardized\\ Residuals}|}$');\n",
    "        return ax\n",
    "\n",
    "    def leverage_plot(self, ax=None, high_leverage_threshold=False, cooks_threshold='baseR'):\n",
    "        \"\"\"\n",
    "        Residual vs Leverage plot\n",
    "\n",
    "        Points falling outside Cook's distance curves are considered observation that can sway the fit\n",
    "        aka are influential.\n",
    "        Good to have none outside the curves.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        ax.scatter(\n",
    "            self.leverage,\n",
    "            self.residual_norm,\n",
    "            alpha=0.5);\n",
    "\n",
    "        sns.regplot(\n",
    "            x=self.leverage,\n",
    "            y=self.residual_norm,\n",
    "            scatter=False,\n",
    "            ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        leverage_top_3 = np.flip(np.argsort(self.cooks_distance), 0)[:3]\n",
    "        for i in leverage_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.leverage[i], self.residual_norm[i]),\n",
    "                color = 'C3')\n",
    "\n",
    "        factors = []\n",
    "        if cooks_threshold == 'baseR' or cooks_threshold is None:\n",
    "            factors = [1, 0.5]\n",
    "        elif cooks_threshold == 'convention':\n",
    "            factors = [4/self.nresids]\n",
    "        elif cooks_threshold == 'dof':\n",
    "            factors = [4/ (self.nresids - self.nparams)]\n",
    "        else:\n",
    "            raise ValueError(\"threshold_method must be one of the following: 'convention', 'dof', or 'baseR' (default)\")\n",
    "        for i, factor in enumerate(factors):\n",
    "            label = \"Cook's distance\" if i == 0 else None\n",
    "            xtemp, ytemp = self.__cooks_dist_line(factor)\n",
    "            ax.plot(xtemp, ytemp, label=label, lw=1.25, ls='--', color='red')\n",
    "            ax.plot(xtemp, np.negative(ytemp), lw=1.25, ls='--', color='red')\n",
    "\n",
    "        if high_leverage_threshold:\n",
    "            high_leverage = 2 * self.nparams / self.nresids\n",
    "            if max(self.leverage) > high_leverage:\n",
    "                ax.axvline(high_leverage, label='High leverage', ls='-.', color='purple', lw=1)\n",
    "\n",
    "        ax.axhline(0, ls='dotted', color='black', lw=1.25)\n",
    "        ax.set_xlim(0, max(self.leverage)+0.01)\n",
    "        ax.set_ylim(min(self.residual_norm)-0.1, max(self.residual_norm)+0.1)\n",
    "        ax.set_title('Residuals vs Leverage', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Leverage')\n",
    "        ax.set_ylabel('Standardized Residuals')\n",
    "        plt.legend(loc='best')\n",
    "        return ax\n",
    "\n",
    "    def vif_table(self):\n",
    "        \"\"\"\n",
    "        VIF table\n",
    "\n",
    "        VIF, the variance inflation factor, is a measure of multicollinearity.\n",
    "        VIF > 5 for a variable indicates that it is highly collinear with the\n",
    "        other input variables.\n",
    "        \"\"\"\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df[\"Features\"] = self.xvar_names\n",
    "        vif_df[\"VIF Factor\"] = [variance_inflation_factor(self.xvar, i) for i in range(self.xvar.shape[1])]\n",
    "\n",
    "        return (vif_df\n",
    "                .sort_values(\"VIF Factor\")\n",
    "                .round(2))\n",
    "\n",
    "\n",
    "    def __cooks_dist_line(self, factor):\n",
    "        \"\"\"\n",
    "        Helper function for plotting Cook's distance curves\n",
    "        \"\"\"\n",
    "        p = self.nparams\n",
    "        formula = lambda x: np.sqrt((factor * p * (1 - x)) / x)\n",
    "        x = np.linspace(0.001, max(self.leverage), 50)\n",
    "        y = formula(x)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __qq_top_resid(self, quantiles, top_residual_indices):\n",
    "        \"\"\"\n",
    "        Helper generator function yielding the index and coordinates\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "        quant_index = 0\n",
    "        previous_is_negative = None\n",
    "        for resid_index in top_residual_indices:\n",
    "            y = self.residual_norm[resid_index]\n",
    "            is_negative = y < 0\n",
    "            if previous_is_negative == None or previous_is_negative == is_negative:\n",
    "                offset += 1\n",
    "            else:\n",
    "                quant_index -= offset\n",
    "            x = quantiles[quant_index] if is_negative else np.flip(quantiles, 0)[quant_index]\n",
    "            quant_index += 1\n",
    "            previous_is_negative = is_negative\n",
    "            yield resid_index, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Word', 'Frequency', 'CD', 'Concreteness', 'Morphemes', 'Phonemes',\n",
       "       'ON_Size', 'PN_Size', 'Letters', 'Syllables', 'BOI', 'Cue Memorability',\n",
       "       'Target Memorability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Regression for Cue Memorability\n",
    "res_cue = smf.ols(\n",
    "    formula=\"Q('Cue Memorability') ~ Frequency + CD + Concreteness + Morphemes + ON_Size + PN_Size + BOI + Phonemes + Letters + Syllables\",\n",
    "    data=merged_df\n",
    ").fit()\n",
    "\n",
    "# Regression for Target Memorability\n",
    "res_target = smf.ols(\n",
    "    formula=\"Q('Target Memorability') ~ Frequency + CD + Concreteness + Morphemes + ON_Size + PN_Size + BOI + Phonemes + Letters + Syllables\",\n",
    "    data=merged_df\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_cue = LinearRegDiagnostic(res_cue)\n",
    "cls_target = LinearRegDiagnostic(res_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANUSKA MAITY\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ON_Size</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PN_Size</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Concreteness</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOI</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frequency</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CD</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morphemes</td>\n",
       "      <td>41.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Letters</td>\n",
       "      <td>42.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Phonemes</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Syllables</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Features  VIF Factor\n",
       "5        ON_Size        1.21\n",
       "6        PN_Size        1.97\n",
       "3   Concreteness        2.75\n",
       "7            BOI        2.77\n",
       "1      Frequency        3.38\n",
       "2             CD        3.72\n",
       "4      Morphemes       41.83\n",
       "9        Letters       42.95\n",
       "0      Intercept       56.58\n",
       "8       Phonemes         inf\n",
       "10     Syllables         inf"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cls_cue.vif_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANUSKA MAITY\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ON_Size</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PN_Size</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Concreteness</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOI</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frequency</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CD</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morphemes</td>\n",
       "      <td>41.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Letters</td>\n",
       "      <td>42.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Phonemes</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Syllables</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Features  VIF Factor\n",
       "5        ON_Size        1.21\n",
       "6        PN_Size        1.97\n",
       "3   Concreteness        2.75\n",
       "7            BOI        2.77\n",
       "1      Frequency        3.38\n",
       "2             CD        3.72\n",
       "4      Morphemes       41.83\n",
       "9        Letters       42.95\n",
       "0      Intercept       56.58\n",
       "8       Phonemes         inf\n",
       "10     Syllables         inf"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_target.vif_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUE VIF(after removing WF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ON_Size</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PN_Size</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morphemes</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Concreteness</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOI</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>51.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Features  VIF Factor\n",
       "4       ON_Size        1.18\n",
       "1            CD        1.18\n",
       "5       PN_Size        1.75\n",
       "3     Morphemes        1.77\n",
       "2  Concreteness        2.74\n",
       "6           BOI        2.77\n",
       "0     Intercept       51.46"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Remove highest VIF variable (Phonemes) from formula\n",
    "new_formula = \"Q('Cue Memorability') ~ CD + Concreteness + Morphemes + ON_Size + PN_Size + BOI\"\n",
    "\n",
    "# Create new model without the high VIF variable\n",
    "new_cue_model = sm.formula.ols(new_formula, data=merged_df).fit()\n",
    "\n",
    "# Check new model's VIF\n",
    "new_cls_cue = LinearRegDiagnostic(new_cue_model)\n",
    "new_cls_cue.vif_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TARGET VIF(after removing WF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ON_Size</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PN_Size</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morphemes</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Concreteness</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOI</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>51.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Features  VIF Factor\n",
       "4       ON_Size        1.18\n",
       "1            CD        1.18\n",
       "5       PN_Size        1.75\n",
       "3     Morphemes        1.77\n",
       "2  Concreteness        2.74\n",
       "6           BOI        2.77\n",
       "0     Intercept       51.46"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove highest VIF variable (Phonemes) from formula\n",
    "new_formula = \"Q('Target Memorability') ~ CD + Concreteness + Morphemes + ON_Size + PN_Size + BOI\"\n",
    "\n",
    "# Create new model without the high VIF variable\n",
    "new_target_model = sm.formula.ols(new_formula, data=merged_df).fit()\n",
    "\n",
    "# Check new model's VIF\n",
    "new_cls_target = LinearRegDiagnostic(new_cue_model)\n",
    "new_cls_target.vif_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
